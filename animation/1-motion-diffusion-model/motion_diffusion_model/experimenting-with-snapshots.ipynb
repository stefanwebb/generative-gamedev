{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See whether I can convert a MDM snapshot to safetensors and load in my model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = \"/home/stefanwebb/code/python/motion-diffusion-model/save/my_humanml_trans_enc_512/model000600161.pt\"\n",
    "model_snapshot = torch.load(snapshot, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_process.poseEmbedding.weight',\n",
       " 'input_process.poseEmbedding.bias',\n",
       " 'sequence_pos_encoder.pe',\n",
       " 'seqTransEncoder.layers.0.self_attn.in_proj_weight',\n",
       " 'seqTransEncoder.layers.0.self_attn.in_proj_bias',\n",
       " 'seqTransEncoder.layers.0.self_attn.out_proj.weight',\n",
       " 'seqTransEncoder.layers.0.self_attn.out_proj.bias',\n",
       " 'seqTransEncoder.layers.0.linear1.weight',\n",
       " 'seqTransEncoder.layers.0.linear1.bias',\n",
       " 'seqTransEncoder.layers.0.linear2.weight',\n",
       " 'seqTransEncoder.layers.0.linear2.bias',\n",
       " 'seqTransEncoder.layers.0.norm1.weight',\n",
       " 'seqTransEncoder.layers.0.norm1.bias',\n",
       " 'seqTransEncoder.layers.0.norm2.weight',\n",
       " 'seqTransEncoder.layers.0.norm2.bias',\n",
       " 'seqTransEncoder.layers.1.self_attn.in_proj_weight',\n",
       " 'seqTransEncoder.layers.1.self_attn.in_proj_bias',\n",
       " 'seqTransEncoder.layers.1.self_attn.out_proj.weight',\n",
       " 'seqTransEncoder.layers.1.self_attn.out_proj.bias',\n",
       " 'seqTransEncoder.layers.1.linear1.weight',\n",
       " 'seqTransEncoder.layers.1.linear1.bias',\n",
       " 'seqTransEncoder.layers.1.linear2.weight',\n",
       " 'seqTransEncoder.layers.1.linear2.bias',\n",
       " 'seqTransEncoder.layers.1.norm1.weight',\n",
       " 'seqTransEncoder.layers.1.norm1.bias',\n",
       " 'seqTransEncoder.layers.1.norm2.weight',\n",
       " 'seqTransEncoder.layers.1.norm2.bias',\n",
       " 'seqTransEncoder.layers.2.self_attn.in_proj_weight',\n",
       " 'seqTransEncoder.layers.2.self_attn.in_proj_bias',\n",
       " 'seqTransEncoder.layers.2.self_attn.out_proj.weight',\n",
       " 'seqTransEncoder.layers.2.self_attn.out_proj.bias',\n",
       " 'seqTransEncoder.layers.2.linear1.weight',\n",
       " 'seqTransEncoder.layers.2.linear1.bias',\n",
       " 'seqTransEncoder.layers.2.linear2.weight',\n",
       " 'seqTransEncoder.layers.2.linear2.bias',\n",
       " 'seqTransEncoder.layers.2.norm1.weight',\n",
       " 'seqTransEncoder.layers.2.norm1.bias',\n",
       " 'seqTransEncoder.layers.2.norm2.weight',\n",
       " 'seqTransEncoder.layers.2.norm2.bias',\n",
       " 'seqTransEncoder.layers.3.self_attn.in_proj_weight',\n",
       " 'seqTransEncoder.layers.3.self_attn.in_proj_bias',\n",
       " 'seqTransEncoder.layers.3.self_attn.out_proj.weight',\n",
       " 'seqTransEncoder.layers.3.self_attn.out_proj.bias',\n",
       " 'seqTransEncoder.layers.3.linear1.weight',\n",
       " 'seqTransEncoder.layers.3.linear1.bias',\n",
       " 'seqTransEncoder.layers.3.linear2.weight',\n",
       " 'seqTransEncoder.layers.3.linear2.bias',\n",
       " 'seqTransEncoder.layers.3.norm1.weight',\n",
       " 'seqTransEncoder.layers.3.norm1.bias',\n",
       " 'seqTransEncoder.layers.3.norm2.weight',\n",
       " 'seqTransEncoder.layers.3.norm2.bias',\n",
       " 'seqTransEncoder.layers.4.self_attn.in_proj_weight',\n",
       " 'seqTransEncoder.layers.4.self_attn.in_proj_bias',\n",
       " 'seqTransEncoder.layers.4.self_attn.out_proj.weight',\n",
       " 'seqTransEncoder.layers.4.self_attn.out_proj.bias',\n",
       " 'seqTransEncoder.layers.4.linear1.weight',\n",
       " 'seqTransEncoder.layers.4.linear1.bias',\n",
       " 'seqTransEncoder.layers.4.linear2.weight',\n",
       " 'seqTransEncoder.layers.4.linear2.bias',\n",
       " 'seqTransEncoder.layers.4.norm1.weight',\n",
       " 'seqTransEncoder.layers.4.norm1.bias',\n",
       " 'seqTransEncoder.layers.4.norm2.weight',\n",
       " 'seqTransEncoder.layers.4.norm2.bias',\n",
       " 'seqTransEncoder.layers.5.self_attn.in_proj_weight',\n",
       " 'seqTransEncoder.layers.5.self_attn.in_proj_bias',\n",
       " 'seqTransEncoder.layers.5.self_attn.out_proj.weight',\n",
       " 'seqTransEncoder.layers.5.self_attn.out_proj.bias',\n",
       " 'seqTransEncoder.layers.5.linear1.weight',\n",
       " 'seqTransEncoder.layers.5.linear1.bias',\n",
       " 'seqTransEncoder.layers.5.linear2.weight',\n",
       " 'seqTransEncoder.layers.5.linear2.bias',\n",
       " 'seqTransEncoder.layers.5.norm1.weight',\n",
       " 'seqTransEncoder.layers.5.norm1.bias',\n",
       " 'seqTransEncoder.layers.5.norm2.weight',\n",
       " 'seqTransEncoder.layers.5.norm2.bias',\n",
       " 'seqTransEncoder.layers.6.self_attn.in_proj_weight',\n",
       " 'seqTransEncoder.layers.6.self_attn.in_proj_bias',\n",
       " 'seqTransEncoder.layers.6.self_attn.out_proj.weight',\n",
       " 'seqTransEncoder.layers.6.self_attn.out_proj.bias',\n",
       " 'seqTransEncoder.layers.6.linear1.weight',\n",
       " 'seqTransEncoder.layers.6.linear1.bias',\n",
       " 'seqTransEncoder.layers.6.linear2.weight',\n",
       " 'seqTransEncoder.layers.6.linear2.bias',\n",
       " 'seqTransEncoder.layers.6.norm1.weight',\n",
       " 'seqTransEncoder.layers.6.norm1.bias',\n",
       " 'seqTransEncoder.layers.6.norm2.weight',\n",
       " 'seqTransEncoder.layers.6.norm2.bias',\n",
       " 'seqTransEncoder.layers.7.self_attn.in_proj_weight',\n",
       " 'seqTransEncoder.layers.7.self_attn.in_proj_bias',\n",
       " 'seqTransEncoder.layers.7.self_attn.out_proj.weight',\n",
       " 'seqTransEncoder.layers.7.self_attn.out_proj.bias',\n",
       " 'seqTransEncoder.layers.7.linear1.weight',\n",
       " 'seqTransEncoder.layers.7.linear1.bias',\n",
       " 'seqTransEncoder.layers.7.linear2.weight',\n",
       " 'seqTransEncoder.layers.7.linear2.bias',\n",
       " 'seqTransEncoder.layers.7.norm1.weight',\n",
       " 'seqTransEncoder.layers.7.norm1.bias',\n",
       " 'seqTransEncoder.layers.7.norm2.weight',\n",
       " 'seqTransEncoder.layers.7.norm2.bias',\n",
       " 'embed_timestep.sequence_pos_encoder.pe',\n",
       " 'embed_timestep.time_embed.0.weight',\n",
       " 'embed_timestep.time_embed.0.bias',\n",
       " 'embed_timestep.time_embed.2.weight',\n",
       " 'embed_timestep.time_embed.2.bias',\n",
       " 'embed_text.weight',\n",
       " 'embed_text.bias',\n",
       " 'output_process.poseFinal.weight',\n",
       " 'output_process.poseFinal.bias']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_snapshot.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefanwebb/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from model import MotionDiffusionModel\n",
    "model = MotionDiffusionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [x for x, _ in list(model.named_parameters())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder.layers.0.self_attn.in_proj_weight',\n",
       " 'encoder.layers.0.self_attn.in_proj_bias',\n",
       " 'encoder.layers.0.self_attn.out_proj.weight',\n",
       " 'encoder.layers.0.self_attn.out_proj.bias',\n",
       " 'encoder.layers.0.linear1.weight',\n",
       " 'encoder.layers.0.linear1.bias',\n",
       " 'encoder.layers.0.linear2.weight',\n",
       " 'encoder.layers.0.linear2.bias',\n",
       " 'encoder.layers.0.norm1.weight',\n",
       " 'encoder.layers.0.norm1.bias',\n",
       " 'encoder.layers.0.norm2.weight',\n",
       " 'encoder.layers.0.norm2.bias',\n",
       " 'encoder.layers.1.self_attn.in_proj_weight',\n",
       " 'encoder.layers.1.self_attn.in_proj_bias',\n",
       " 'encoder.layers.1.self_attn.out_proj.weight',\n",
       " 'encoder.layers.1.self_attn.out_proj.bias',\n",
       " 'encoder.layers.1.linear1.weight',\n",
       " 'encoder.layers.1.linear1.bias',\n",
       " 'encoder.layers.1.linear2.weight',\n",
       " 'encoder.layers.1.linear2.bias',\n",
       " 'encoder.layers.1.norm1.weight',\n",
       " 'encoder.layers.1.norm1.bias',\n",
       " 'encoder.layers.1.norm2.weight',\n",
       " 'encoder.layers.1.norm2.bias',\n",
       " 'encoder.layers.2.self_attn.in_proj_weight',\n",
       " 'encoder.layers.2.self_attn.in_proj_bias',\n",
       " 'encoder.layers.2.self_attn.out_proj.weight',\n",
       " 'encoder.layers.2.self_attn.out_proj.bias',\n",
       " 'encoder.layers.2.linear1.weight',\n",
       " 'encoder.layers.2.linear1.bias',\n",
       " 'encoder.layers.2.linear2.weight',\n",
       " 'encoder.layers.2.linear2.bias',\n",
       " 'encoder.layers.2.norm1.weight',\n",
       " 'encoder.layers.2.norm1.bias',\n",
       " 'encoder.layers.2.norm2.weight',\n",
       " 'encoder.layers.2.norm2.bias',\n",
       " 'encoder.layers.3.self_attn.in_proj_weight',\n",
       " 'encoder.layers.3.self_attn.in_proj_bias',\n",
       " 'encoder.layers.3.self_attn.out_proj.weight',\n",
       " 'encoder.layers.3.self_attn.out_proj.bias',\n",
       " 'encoder.layers.3.linear1.weight',\n",
       " 'encoder.layers.3.linear1.bias',\n",
       " 'encoder.layers.3.linear2.weight',\n",
       " 'encoder.layers.3.linear2.bias',\n",
       " 'encoder.layers.3.norm1.weight',\n",
       " 'encoder.layers.3.norm1.bias',\n",
       " 'encoder.layers.3.norm2.weight',\n",
       " 'encoder.layers.3.norm2.bias',\n",
       " 'encoder.layers.4.self_attn.in_proj_weight',\n",
       " 'encoder.layers.4.self_attn.in_proj_bias',\n",
       " 'encoder.layers.4.self_attn.out_proj.weight',\n",
       " 'encoder.layers.4.self_attn.out_proj.bias',\n",
       " 'encoder.layers.4.linear1.weight',\n",
       " 'encoder.layers.4.linear1.bias',\n",
       " 'encoder.layers.4.linear2.weight',\n",
       " 'encoder.layers.4.linear2.bias',\n",
       " 'encoder.layers.4.norm1.weight',\n",
       " 'encoder.layers.4.norm1.bias',\n",
       " 'encoder.layers.4.norm2.weight',\n",
       " 'encoder.layers.4.norm2.bias',\n",
       " 'encoder.layers.5.self_attn.in_proj_weight',\n",
       " 'encoder.layers.5.self_attn.in_proj_bias',\n",
       " 'encoder.layers.5.self_attn.out_proj.weight',\n",
       " 'encoder.layers.5.self_attn.out_proj.bias',\n",
       " 'encoder.layers.5.linear1.weight',\n",
       " 'encoder.layers.5.linear1.bias',\n",
       " 'encoder.layers.5.linear2.weight',\n",
       " 'encoder.layers.5.linear2.bias',\n",
       " 'encoder.layers.5.norm1.weight',\n",
       " 'encoder.layers.5.norm1.bias',\n",
       " 'encoder.layers.5.norm2.weight',\n",
       " 'encoder.layers.5.norm2.bias',\n",
       " 'encoder.layers.6.self_attn.in_proj_weight',\n",
       " 'encoder.layers.6.self_attn.in_proj_bias',\n",
       " 'encoder.layers.6.self_attn.out_proj.weight',\n",
       " 'encoder.layers.6.self_attn.out_proj.bias',\n",
       " 'encoder.layers.6.linear1.weight',\n",
       " 'encoder.layers.6.linear1.bias',\n",
       " 'encoder.layers.6.linear2.weight',\n",
       " 'encoder.layers.6.linear2.bias',\n",
       " 'encoder.layers.6.norm1.weight',\n",
       " 'encoder.layers.6.norm1.bias',\n",
       " 'encoder.layers.6.norm2.weight',\n",
       " 'encoder.layers.6.norm2.bias',\n",
       " 'encoder.layers.7.self_attn.in_proj_weight',\n",
       " 'encoder.layers.7.self_attn.in_proj_bias',\n",
       " 'encoder.layers.7.self_attn.out_proj.weight',\n",
       " 'encoder.layers.7.self_attn.out_proj.bias',\n",
       " 'encoder.layers.7.linear1.weight',\n",
       " 'encoder.layers.7.linear1.bias',\n",
       " 'encoder.layers.7.linear2.weight',\n",
       " 'encoder.layers.7.linear2.bias',\n",
       " 'encoder.layers.7.norm1.weight',\n",
       " 'encoder.layers.7.norm1.bias',\n",
       " 'encoder.layers.7.norm2.weight',\n",
       " 'encoder.layers.7.norm2.bias',\n",
       " 'timestep_encoder.time_embed.0.weight',\n",
       " 'timestep_encoder.time_embed.0.bias',\n",
       " 'timestep_encoder.time_embed.2.weight',\n",
       " 'timestep_encoder.time_embed.2.bias',\n",
       " 'input_proj.weight',\n",
       " 'input_proj.bias',\n",
       " 'output_proj.weight',\n",
       " 'output_proj.bias',\n",
       " 'text_proj.weight',\n",
       " 'text_proj.bias']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacements = [\n",
    "    ('seqTransEncoder', 'encoder'),\n",
    "    ('embed_timestep', 'timestep_encoder'),\n",
    "    ('embed_text', 'text_proj'),\n",
    "    ('output_process.poseFinal', 'output_proj'),\n",
    "    ('sequence_pos_encoder', 'pos_encoder'),\n",
    "    ('input_process.poseEmbedding', 'input_proj'),\n",
    "]\n",
    "\n",
    "def map_param_name(param_name):\n",
    "    for old, new in replacements:\n",
    "        param_name = param_name.replace(old, new)\n",
    "    return param_name\n",
    "\n",
    "param_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_names = list(sorted([ map_param_name(x) for x in list(model_snapshot.keys()) if not x.endswith('pe')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder.layers.0.linear1.bias',\n",
       " 'encoder.layers.0.linear1.weight',\n",
       " 'encoder.layers.0.linear2.bias',\n",
       " 'encoder.layers.0.linear2.weight',\n",
       " 'encoder.layers.0.norm1.bias',\n",
       " 'encoder.layers.0.norm1.weight',\n",
       " 'encoder.layers.0.norm2.bias',\n",
       " 'encoder.layers.0.norm2.weight',\n",
       " 'encoder.layers.0.self_attn.in_proj_bias',\n",
       " 'encoder.layers.0.self_attn.in_proj_weight',\n",
       " 'encoder.layers.0.self_attn.out_proj.bias',\n",
       " 'encoder.layers.0.self_attn.out_proj.weight',\n",
       " 'encoder.layers.1.linear1.bias',\n",
       " 'encoder.layers.1.linear1.weight',\n",
       " 'encoder.layers.1.linear2.bias',\n",
       " 'encoder.layers.1.linear2.weight',\n",
       " 'encoder.layers.1.norm1.bias',\n",
       " 'encoder.layers.1.norm1.weight',\n",
       " 'encoder.layers.1.norm2.bias',\n",
       " 'encoder.layers.1.norm2.weight',\n",
       " 'encoder.layers.1.self_attn.in_proj_bias',\n",
       " 'encoder.layers.1.self_attn.in_proj_weight',\n",
       " 'encoder.layers.1.self_attn.out_proj.bias',\n",
       " 'encoder.layers.1.self_attn.out_proj.weight',\n",
       " 'encoder.layers.2.linear1.bias',\n",
       " 'encoder.layers.2.linear1.weight',\n",
       " 'encoder.layers.2.linear2.bias',\n",
       " 'encoder.layers.2.linear2.weight',\n",
       " 'encoder.layers.2.norm1.bias',\n",
       " 'encoder.layers.2.norm1.weight',\n",
       " 'encoder.layers.2.norm2.bias',\n",
       " 'encoder.layers.2.norm2.weight',\n",
       " 'encoder.layers.2.self_attn.in_proj_bias',\n",
       " 'encoder.layers.2.self_attn.in_proj_weight',\n",
       " 'encoder.layers.2.self_attn.out_proj.bias',\n",
       " 'encoder.layers.2.self_attn.out_proj.weight',\n",
       " 'encoder.layers.3.linear1.bias',\n",
       " 'encoder.layers.3.linear1.weight',\n",
       " 'encoder.layers.3.linear2.bias',\n",
       " 'encoder.layers.3.linear2.weight',\n",
       " 'encoder.layers.3.norm1.bias',\n",
       " 'encoder.layers.3.norm1.weight',\n",
       " 'encoder.layers.3.norm2.bias',\n",
       " 'encoder.layers.3.norm2.weight',\n",
       " 'encoder.layers.3.self_attn.in_proj_bias',\n",
       " 'encoder.layers.3.self_attn.in_proj_weight',\n",
       " 'encoder.layers.3.self_attn.out_proj.bias',\n",
       " 'encoder.layers.3.self_attn.out_proj.weight',\n",
       " 'encoder.layers.4.linear1.bias',\n",
       " 'encoder.layers.4.linear1.weight',\n",
       " 'encoder.layers.4.linear2.bias',\n",
       " 'encoder.layers.4.linear2.weight',\n",
       " 'encoder.layers.4.norm1.bias',\n",
       " 'encoder.layers.4.norm1.weight',\n",
       " 'encoder.layers.4.norm2.bias',\n",
       " 'encoder.layers.4.norm2.weight',\n",
       " 'encoder.layers.4.self_attn.in_proj_bias',\n",
       " 'encoder.layers.4.self_attn.in_proj_weight',\n",
       " 'encoder.layers.4.self_attn.out_proj.bias',\n",
       " 'encoder.layers.4.self_attn.out_proj.weight',\n",
       " 'encoder.layers.5.linear1.bias',\n",
       " 'encoder.layers.5.linear1.weight',\n",
       " 'encoder.layers.5.linear2.bias',\n",
       " 'encoder.layers.5.linear2.weight',\n",
       " 'encoder.layers.5.norm1.bias',\n",
       " 'encoder.layers.5.norm1.weight',\n",
       " 'encoder.layers.5.norm2.bias',\n",
       " 'encoder.layers.5.norm2.weight',\n",
       " 'encoder.layers.5.self_attn.in_proj_bias',\n",
       " 'encoder.layers.5.self_attn.in_proj_weight',\n",
       " 'encoder.layers.5.self_attn.out_proj.bias',\n",
       " 'encoder.layers.5.self_attn.out_proj.weight',\n",
       " 'encoder.layers.6.linear1.bias',\n",
       " 'encoder.layers.6.linear1.weight',\n",
       " 'encoder.layers.6.linear2.bias',\n",
       " 'encoder.layers.6.linear2.weight',\n",
       " 'encoder.layers.6.norm1.bias',\n",
       " 'encoder.layers.6.norm1.weight',\n",
       " 'encoder.layers.6.norm2.bias',\n",
       " 'encoder.layers.6.norm2.weight',\n",
       " 'encoder.layers.6.self_attn.in_proj_bias',\n",
       " 'encoder.layers.6.self_attn.in_proj_weight',\n",
       " 'encoder.layers.6.self_attn.out_proj.bias',\n",
       " 'encoder.layers.6.self_attn.out_proj.weight',\n",
       " 'encoder.layers.7.linear1.bias',\n",
       " 'encoder.layers.7.linear1.weight',\n",
       " 'encoder.layers.7.linear2.bias',\n",
       " 'encoder.layers.7.linear2.weight',\n",
       " 'encoder.layers.7.norm1.bias',\n",
       " 'encoder.layers.7.norm1.weight',\n",
       " 'encoder.layers.7.norm2.bias',\n",
       " 'encoder.layers.7.norm2.weight',\n",
       " 'encoder.layers.7.self_attn.in_proj_bias',\n",
       " 'encoder.layers.7.self_attn.in_proj_weight',\n",
       " 'encoder.layers.7.self_attn.out_proj.bias',\n",
       " 'encoder.layers.7.self_attn.out_proj.weight',\n",
       " 'input_proj.bias',\n",
       " 'input_proj.weight',\n",
       " 'output_proj.bias',\n",
       " 'output_proj.weight',\n",
       " 'text_proj.bias',\n",
       " 'text_proj.weight',\n",
       " 'timestep_encoder.time_embed.0.bias',\n",
       " 'timestep_encoder.time_embed.0.weight',\n",
       " 'timestep_encoder.time_embed.2.bias',\n",
       " 'timestep_encoder.time_embed.2.weight']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = list(sorted([x for x, _ in list(model.named_parameters())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 106)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param_names), len(mapped_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(param_names, mapped_names):\n",
    "    print(x == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_state_dict = {map_param_name(k): v for k, v in model_snapshot.items() if map_param_name(k) != 'pos_encoder.pe'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(mapped_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import save_file\n",
    "save_file(mapped_state_dict, \"model.safetensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing input/output to actual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../../../../motion-diffusion-model/vars.pkl', 'rb') as f:\n",
    "    args = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = args['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mask', 'lengths', 'text', 'tokens', 'scale', 'text_embed']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the person jumped twice.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "clip_model = SentenceTransformer('clip-ViT-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_emb = clip_model.encode(y['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0157e-04,  3.3247e-04, -3.8102e-04,  ...,  3.8391e-04,\n",
       "          -6.4895e-06,  3.8475e-04],\n",
       "         [-1.0157e-04,  3.3247e-04, -3.8102e-04,  ...,  3.8391e-04,\n",
       "          -6.4895e-06,  3.8475e-04],\n",
       "         [-1.0157e-04,  3.3247e-04, -3.8102e-04,  ...,  3.8391e-04,\n",
       "          -6.4895e-06,  3.8475e-04],\n",
       "         [-1.0157e-04,  3.3247e-04, -3.8102e-04,  ...,  3.8391e-04,\n",
       "          -6.4895e-06,  3.8475e-04],\n",
       "         [-1.0157e-04,  3.3247e-04, -3.8102e-04,  ...,  3.8391e-04,\n",
       "          -6.4895e-06,  3.8475e-04],\n",
       "         [-1.0157e-04,  3.3247e-04, -3.8102e-04,  ...,  3.8391e-04,\n",
       "          -6.4895e-06,  3.8475e-04]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CLIP embeddings agree within numerical tolerance\n",
    "y['text_embed'].cpu() - text_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefanwebb/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MotionDiffusionModel' object has no attribute 'embed_timestep'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m MotionDiffusionModel()\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(mapped_state_dict, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimesteps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1750\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/python/generative-gamedev/animation/1-motion-diffusion-model/motion_diffusion_model/model.py:83\u001b[0m, in \u001b[0;36mMotionDiffusionModel.forward\u001b[0;34m(self, x, timesteps, y)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03mx: [batch_size, njoints, nfeats, max_frames], denoted x_t in the paper\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03mtimesteps: [batch_size] (int)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m bs, njoints, nfeats, nframes \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 83\u001b[0m time_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_timestep\u001b[49m(timesteps)  \u001b[38;5;66;03m# [1, bs=6, d=512]\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# TODO: Masking frames, dimensions\u001b[39;00m\n\u001b[1;32m     86\u001b[0m text_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_proj(y[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_embed\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1915\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1914\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1915\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1917\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MotionDiffusionModel' object has no attribute 'embed_timestep'"
     ]
    }
   ],
   "source": [
    "from model import MotionDiffusionModel\n",
    "model = MotionDiffusionModel()\n",
    "model.load_state_dict(mapped_state_dict, strict=False)\n",
    "\n",
    "output = model(args['x'], args['timesteps'], args['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
